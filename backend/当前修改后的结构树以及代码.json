{
    "directory_tree": {
        "Cargo.toml": "ignored_file",
        "Cargo.lock": "ignored_file",
        ".qdrant-initialized": "file",
        "rs结构树.py": "file",
        "qdrant": "file",
        "rs结构树.py:Zone.Identifier": "file",
        "snapshots": {
            "tmp": {
                "upload": {}
            }
        },
        "agent_memos": {
            "Cargo.toml": "ignored_file",
            "src": {
                "db.rs": "file",
                "lib.rs": "file",
                "embedding.rs": "file",
                "prompts.rs": "file"
            }
        },
        "memos_core": {
            "Cargo.toml": "ignored_file",
            "src": {
                "lib.rs": "file"
            }
        },
        "orchestrator": {
            "Cargo.toml": "ignored_file",
            "src": {
                "orchestrator.rs": "file",
                "lib.rs": "file",
                "prompts.rs": "file"
            }
        },
        "memos_cli": {
            "Cargo.toml": "ignored_file",
            "src": {
                "main.rs": "file"
            }
        }
    },
    "core_code_info": [
        {
            "file_path": "agent_memos/src/db.rs",
            "content": "use r2d2_sqlite::SqliteConnectionManager;\nuse rusqlite::Result;\n\n// 定义连接池的类型别名，方便使用\npub type DbPool = r2d2::Pool<SqliteConnectionManager>;\n\n/// 初始化数据库并创建表\npub fn init_db(pool: &DbPool) -> Result<()> {\n    // 从连接池中获取一个连接\n    let conn = pool.get().expect(\"Failed to get DB connection from pool\");\n    \n    // 创建 'facts' 表，如果它不存在的话\n    // 我们在这里预留了未来需要的字段\n    conn.execute(\n        \"CREATE TABLE IF NOT EXISTS facts (\n            id INTEGER PRIMARY KEY,\n            type TEXT NOT NULL,\n            content TEXT NOT NULL,\n            metadata TEXT,\n            status TEXT NOT NULL DEFAULT 'active',\n            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n        )\",\n        [],\n    )?;\n\n    println!(\"[MemosAgent-DB] Database initialized and 'facts' table created.\");\n    Ok(())\n}"
        },
        {
            "file_path": "agent_memos/src/lib.rs",
            "content": "// agent_memos/src/lib.rs\n\n// use 声明也相应简化\nuse memos_core::{Agent, Command, Response};\nuse async_trait::async_trait;\nuse r2d2_sqlite::SqliteConnectionManager;\nuse r2d2::Pool;\nuse chrono::Utc;\nuse std::collections::HashMap;\nuse qdrant_client::qdrant::{PointStruct, Vector, VectorParamsBuilder, CreateCollectionBuilder, Distance, UpsertPointsBuilder, SearchPointsBuilder, ScoredPoint, point_id, vector::Vector as QdrantVectorEnums, DenseVector};\nuse qdrant_client::{Payload, Qdrant};\nuse serde_json::json;\nuse std::any::Any;\n\n// 移除所有与LLM相关的 struct 定义（EmbeddingRequest除外）\n#[derive(serde::Serialize)]\nstruct EmbeddingRequest<'a> {\n    content: &'a str,\n}\n#[derive(Debug, serde::Deserialize)]\nstruct EmbeddingData {\n    embedding: Vec<Vec<f32>>,\n}\n#[derive(Debug, serde::Deserialize)]\nstruct EmbeddingResponse(Vec<EmbeddingData>);\n\ntype DbPool = Pool<SqliteConnectionManager>;\nconst COLLECTION_NAME: &str = \"memos\";\nconst EMBEDDING_DIM: u64 = 1024; \n\npub struct MemosAgent {\n    sql_pool: DbPool,\n    qdrant_client: Qdrant, \n}\n\nimpl MemosAgent {\n    pub async fn new(qdrant_url: &str) -> Result<Self, anyhow::Error> {\n        let home_dir = dirs::home_dir().ok_or_else(|| anyhow::anyhow!(\"Could not find home directory\"))?;\n        let db_dir = home_dir.join(\".memos_agent\");\n        std::fs::create_dir_all(&db_dir)?;\n        let sql_db_path = db_dir.join(\"memos.db\");\n        let manager = SqliteConnectionManager::file(sql_db_path);\n        let sql_pool = Pool::new(manager)?;\n        let conn = sql_pool.get()?;\n        conn.execute(\n            \"CREATE TABLE IF NOT EXISTS facts (id INTEGER PRIMARY KEY, content TEXT NOT NULL, created_at TEXT NOT NULL)\",\n            [],\n        )?;\n        println!(\"[MemosAgent-DB] SQLite database initialized.\");\n\n        let qdrant_client = Qdrant::from_url(qdrant_url).build()?;\n        println!(\"[MemosAgent-DB] Qdrant client initialized.\");\n\n        let collection_exists = qdrant_client.collection_exists(COLLECTION_NAME).await?;\n        if !collection_exists {\n            println!(\"[MemosAgent-DB] Collection '{}' not found. Creating...\", COLLECTION_NAME);\n            qdrant_client.create_collection(\n                CreateCollectionBuilder::new(COLLECTION_NAME)\n                    .vectors_config(VectorParamsBuilder::new(EMBEDDING_DIM, Distance::Cosine))\n            ).await?;\n            println!(\"[MemosAgent-DB] Qdrant collection '{}' created.\", COLLECTION_NAME);\n        } else {\n            println!(\"[MemosAgent-DB] Found existing collection '{}'.\", COLLECTION_NAME);\n        }\n\n        Ok(Self { sql_pool, qdrant_client })\n    }\n\n    // --- `save` 方法保持核心逻辑，但可以简化，因为它总是被调用\n    pub async fn save(&self, content: &str) -> Result<(), anyhow::Error> {\n        println!(\"[MemosAgent] Saving memo: '{}'\", content);\n        let conn = self.sql_pool.get()?;\n        let now = Utc::now().to_rfc3339();\n        conn.execute(\"INSERT INTO facts (content, created_at) VALUES (?1, ?2)\", &[content, &now])?;\n        let memo_id = conn.last_insert_rowid();\n        println!(\"[MemosAgent-DB] Saved to SQLite with ID: {}\", memo_id);\n        let vector_data = self.get_embedding(content).await?;\n        let qdrant_vector = Vector {\n            vector: Some(QdrantVectorEnums::Dense(DenseVector { data: vector_data })),\n            ..Default::default()\n        };\n        let payload: Payload = json!({\"content\": content,\"created_at\": now}).try_into().unwrap();\n        let points = vec![PointStruct::new(memo_id as u64, qdrant_vector, payload)];\n        self.qdrant_client.upsert_points(UpsertPointsBuilder::new(COLLECTION_NAME.to_string(), points)).await?;\n        println!(\"[MemosAgent-DB] Upserted point to Qdrant with ID: {}\", memo_id);\n        Ok(())\n    }\n\n    // --- 全新的 `recall` 方法，零LLM调用 ---\n    pub async fn recall(&self, query_text: &str) -> Result<Response, anyhow::Error> {\n        println!(\"[MemosAgent] Recalling for: '{}'\", query_text);\n        \n        // 步骤 1: 嵌入用户原始查询 (不再有HyDE)\n        let query_vector = self.get_embedding(query_text).await?;\n\n        // 步骤 2: (简化版) 只进行向量和关键词检索\n        let keywords = self.extract_keywords(query_text);\n\n        let (vector_result, keyword_result) = tokio::try_join!(\n            // vector search\n            async {\n                self.qdrant_client.search_points(\n                    SearchPointsBuilder::new(COLLECTION_NAME, query_vector, 10).with_payload(true)\n                ).await.map_err(|e| anyhow::anyhow!(\"Vector search failed: {}\", e))\n            },\n            // keyword search\n            async {\n                if keywords.is_empty() { return Ok(vec![]); } \n                use qdrant_client::qdrant::{r#match::MatchValue, Condition, Filter};\n                let filter = Filter::must(keywords.iter().map(|k| Condition::matches(\"content\", MatchValue::Text(k.clone()))));\n                let scroll_response = self.qdrant_client.scroll(\n                    qdrant_client::qdrant::ScrollPointsBuilder::new(COLLECTION_NAME).filter(filter).limit(10).with_payload(true)\n                ).await.map_err(|e| anyhow::anyhow!(\"Keyword search failed: {}\", e))?;\n                Ok(scroll_response.result.into_iter().map(|p| ScoredPoint { id: p.id, payload: p.payload, score: 1.0, version: 0, vectors: p.vectors, order_value: p.order_value, shard_key: p.shard_key }).collect())\n            }\n        )?;\n\n        // 步骤 3: RRF融合 和 动态阈值过滤\n        let fused_points = self.reciprocal_rank_fusion(vector_result.result, keyword_result, 60);\n        let filtered_points = self.apply_dynamic_threshold(fused_points);\n\n        if filtered_points.is_empty() {\n            return Ok(Response::Text(\"关于这个，我好像没什么印象...\".to_string()));\n        }\n\n        // 步骤 4: 高置信度判断\n        if !filtered_points.is_empty() && filtered_points[0].score > 0.85 {\n            if let Some(content) = filtered_points[0].payload.get(\"content\").and_then(|v| v.as_str()) {\n                println!(\"[MemosAgent] High confidence TOP-1 match found. Returning directly.\");\n                return Ok(Response::Text(content.to_string()));\n            }\n        }\n\n        // 步骤 5: 低置信度时的处理\n        println!(\"[MemosAgent] Low confidence matches. Returning summary.\");\n        let top_results_summary: Vec<String> = filtered_points.iter().take(3).filter_map(|p| {\n            p.payload.get(\"content\").and_then(|v| v.as_str()).map(|s| format!(\"- {}\", s))\n        }).collect();\n\n        let response_text = format!(\n            \"关于“{}”，我没有找到直接的记忆，但发现了一些可能相关的内容：\\n{}\",\n            query_text,\n            top_results_summary.join(\"\\n\")\n        );\n\n        Ok(Response::Text(response_text))\n    }\n\n    // --- 保持不变的辅助函数 ---\n    async fn get_embedding(&self, text: &str) -> Result<Vec<f32>, anyhow::Error> {\n        println!(\"[MemosAgent-Embed] Requesting vector for text: '{}'\", text);\n        let client = reqwest::Client::new();\n        let embedding_url = \"http://localhost:8181/embedding\";\n        let response = client.post(embedding_url).json(&EmbeddingRequest { content: text }).send().await?;\n        if !response.status().is_success() {\n            let error_body = response.text().await?;\n            return Err(anyhow::anyhow!(\"Embedding service returned an error: {}\", error_body));\n        }\n        let mut embedding_response = response.json::<EmbeddingResponse>().await?;\n        if let Some(mut first_item) = embedding_response.0.pop() {\n            if let Some(embedding_vector) = first_item.embedding.pop() {\n                println!(\"[MemosAgent-Embed] Received {}d vector.\", embedding_vector.len());\n                Ok(embedding_vector)\n            } else {\n                Err(anyhow::anyhow!(\"Embedding service returned an item with an empty embedding list.\"))\n            }\n        } else {\n            Err(anyhow::anyhow!(\"Embedding service returned an empty array.\"))\n        }\n    }\n\n    fn extract_keywords(&self, query_text: &str) -> Vec<String> {\n        println!(\"[MemosAgent-Keyword] Extracting keywords with Jieba...\");\n        use jieba_rs::Jieba;\n        use stop_words::{get, LANGUAGE};\n\n        let jieba = Jieba::new();\n        let stop_words = get(LANGUAGE::Chinese);\n\n        let keywords: Vec<String> = jieba.cut_for_search(query_text, true)\n            .into_iter()\n            .map(|s| s.to_lowercase())\n            .filter(|word| !stop_words.contains(word))\n            .collect();\n        \n        println!(\"[MemosAgent-Keyword] Extracted keywords: {:?}\", keywords);\n        keywords\n    }\n    \n    fn reciprocal_rank_fusion(\n        &self, \n        vec_points: Vec<ScoredPoint>, \n        kw_points: Vec<ScoredPoint>,\n        k: u32\n    ) -> Vec<ScoredPoint> {\n        println!(\"[MemosAgent-RRF] Starting Reciprocal Rank Fusion...\");\n        \n        let mut fused_scores: HashMap<u64, f32> = HashMap::new();\n        let mut point_data: HashMap<u64, ScoredPoint> = HashMap::new();\n\n        // 处理向量搜索结果\n        for (rank, point) in vec_points.into_iter().enumerate() {\n            if let Some(point_id::PointIdOptions::Num(memo_id)) = point.id.as_ref().and_then(|p| p.point_id_options.as_ref()) {\n                let score = 1.0 / (k as f32 + (rank + 1) as f32);\n                *fused_scores.entry(*memo_id).or_insert(0.0) += score;\n                point_data.entry(*memo_id).or_insert(point);\n            }\n        }\n\n        // 处理关键词搜索结果\n        for (rank, point) in kw_points.into_iter().enumerate() {\n            if let Some(point_id::PointIdOptions::Num(memo_id)) = point.id.as_ref().and_then(|p| p.point_id_options.as_ref()) {\n                let score = 1.0 / (k as f32 + (rank + 1) as f32); // RRF核心算法\n                *fused_scores.entry(*memo_id).or_insert(0.0) += score;\n                point_data.entry(*memo_id).or_insert(point);\n            }\n        }\n\n        let mut sorted_fused_results: Vec<(u64, f32)> = fused_scores.into_iter().collect();\n        sorted_fused_results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));\n        \n        let final_ranked_list: Vec<ScoredPoint> = sorted_fused_results\n            .into_iter()\n            .filter_map(|(id, rrf_score)| {\n                if let Some(mut point) = point_data.remove(&id) {\n                    point.score = rrf_score;\n                    Some(point)\n                } else {\n                    None\n                }\n            })\n            .collect();\n\n        println!(\"[MemosAgent-RRF] Fusion completed. Final ranked list has {} items.\", final_ranked_list.len());\n        final_ranked_list\n    }\n\n    fn apply_dynamic_threshold(&self, points: Vec<ScoredPoint>) -> Vec<ScoredPoint> {\n        if points.is_empty() {\n            return points;\n        }\n        let scores: Vec<f32> = points.iter().map(|p| p.score).collect();\n        if scores.len() == 1 {\n            return if scores[0] > 0.01 { points } else { vec![] }; // RRF分数很小，阈值也要小\n        }\n        let mut best_drop_index = 0;\n        let mut max_drop = 0.0;\n        for i in 1..scores.len() {\n            let drop = scores[i-1] - scores[i];\n            if drop > max_drop {\n                max_drop = drop;\n                best_drop_index = i;\n            }\n        }\n        // RRF分数断崖会更明显，可以用一个更敏感的比例\n        if max_drop > scores[best_drop_index - 1] * 0.3 && best_drop_index > 0 {\n            println!(\"[MemosAgent-Threshold] Found score drop at index {}, truncating.\", best_drop_index);\n            return points.into_iter().take(best_drop_index).collect();\n        }\n        println!(\"[MemosAgent-Threshold] No significant drop found, returning all points.\");\n        points\n    }\n}\n\n\n#[async_trait]\nimpl Agent for MemosAgent {\n    fn name(&self) -> &'static str { \"memos_agent\" }\n    \n    // interests 现在不再重要，但为了满足 trait 定义，我们保留它\n    fn interests(&self) -> &[&'static str] { &[\"SaveIntent\", \"RecallIntent\"] }\n\n    fn as_any(&self) -> &dyn Any {\n    self}\n\n    async fn handle_command(&self, command: &Command) -> Result<Response, anyhow::Error> {\n        // 这个函数现在只是一个简单的分发器，实际逻辑在 save 和 recall 中\n        // Orchestrator 将直接调用 save 和 recall，所以这个函数可能不会被直接使用\n        // 但为了满足Agent trait，我们保留一个简单的实现\n        match command {\n            Command::ProcessText(text) => {\n                // 默认行为是回忆\n                self.recall(text).await\n            }\n        }\n    }\n}\n"
        },
        {
            "file_path": "agent_memos/src/embedding.rs",
            "content": "// in agent_memos/src/embedding.rs\nuse llama_cpp_2::{\n    context::params::LlamaContextParams, llama_backend::LlamaBackend, llama_batch::LlamaBatch,\n    model::params::LlamaModelParams, model::AddBos, model::LlamaModel,\n};\n\npub struct EmbeddingProvider {\n    model: LlamaModel,\n    backend: LlamaBackend, // 我们需要持有backend以创建context\n}\n\nimpl EmbeddingProvider {\n    pub fn new(model_path: &str) -> Result<Self, anyhow::Error> {\n        println!(\"[EmbeddingProvider] Initializing...\");\n        \n        // 1. 初始化后端 (必须)\n        let backend = LlamaBackend::init()?;\n        \n        // 2. 设置模型参数\n        let model_params = LlamaModelParams::default();\n\n        // 3. 加载模型\n        let model = LlamaModel::load_from_file(&backend, model_path, &model_params)?;\n        println!(\"[EmbeddingProvider] Embedding model loaded successfully from: {}\", model_path);\n\n        Ok(Self { model, backend })\n    }\n\n    pub fn get_embedding(&self, text: &str) -> Result<Vec<f32>, anyhow::Error> {\n        // 1. 设置上下文参数，最关键的是 with_embeddings(true)\n        let ctx_params = LlamaContextParams::default()\n            .with_embeddings(true);\n        \n        // 2. 创建上下文\n        let mut ctx = self.model.new_context(&self.backend, ctx_params)?;\n\n        // 3. 词元化\n        let tokens = self.model.str_to_token(text, AddBos::Always)?;\n\n        // 4. 创建批处理\n        let mut batch = LlamaBatch::new(tokens.len(), 1);\n        batch.add_sequence(&tokens, 0, true)?;\n\n        // 5. 解码\n        ctx.decode(&mut batch)?;\n\n        // 6. 获取嵌入向量\n        // 对于单序列批处理，我们总是获取第0个序列的嵌入\n        let embeddings = ctx.embeddings_seq_ith(0)?;\n\n        Ok(embeddings.to_vec())\n    }\n}"
        },
        {
            "file_path": "agent_memos/src/prompts.rs",
            "content": "// in: agent_memos/src/prompts.rs\n\n// 这是一个公共函数，它返回用于HyDE的系统提示词\npub fn get_hyde_prompt_v2() -> &'static str {\n    // 这就是我们之前在“战果分析”后共同确定的、优化后的V2版本Prompt\n    // 它现在被封装在这里，与核心业务逻辑完全分离\n    r#\"You are a memory retrieval engine. Your sole purpose is to generate a direct, first-person statement that is the most likely answer to the user's question, as if it were a memory record. Do not provide explanations, apologies, or any conversational filler.\n\n<example>\n<user_query>我最喜欢什么编程语言？</user_query>\n<assistant_response>我最喜欢的编程语言是Rust。</assistant_response>\n</example>\n\n<example>\n<user_query>明天下午有什么安排？</user_query>\n<assistant_response>明天下午3点要和产品开会。</assistant_response>\n</example>\n\n<example>\n<user_query>Rust有什么优点？</user_query>\n<assistant_response>Rust语言的优点是高性能、内存安全和强大的并发支持。</assistant_response>\n</example>\n\nNow, generate the memory statement for the user's query.\"#\n}\n\n\n// 新增一个用于最终答案生成的Prompt\npub fn get_synthesis_prompt() -> &'static str {\n    r#\"You are a highly intelligent memory retrieval engine. Your task is to **directly and concisely** answer the user's question based on the provided context of memory snippets.\n\n**Core Instructions:**\n1.  **Direct Answer First**: Get straight to the point. Your entire response should be the direct answer.\n2.  **Be Faithful to Context**: Your answer MUST be based exclusively on the information within the provided memory snippets. Do not add any external information.\n3.  **Synthesize, Don't List**: If multiple snippets provide different parts of an answer, integrate them into a single, coherent, and natural-sounding statement.\n4.  **NO PREAMBLE**: **Do not use introductory phrases** like 'Based on the context', 'According to my memory', 'The provided information states that', or any similar preambles.\n\n**Example:**\n<User_Query>我喜欢什么？</User_Query>\n<Context>\n- 我喜欢打篮球。\n- 我最近开始喜欢听古典音乐。\n- 我很喜欢打排球。\n</Context>\n<Assistant_Response>我喜欢打篮球和排球，并且最近开始欣赏古典音乐。</Assistant_Response>\n\nNow, generate the final answer based on the user's query and the provided context.\"#\n}\n\n\n// 未来我们可以轻松地在这里添加更多的prompt，例如：\n// pub fn get_intent_classification_prompt() -> &'static str { ... }\n// pub fn get_summary_prompt() -> &'static str { ... }"
        },
        {
            "file_path": "memos_core/src/lib.rs",
            "content": "// memos_core/src/lib.rs\nuse std::path::PathBuf;\nuse async_trait::async_trait;\nuse tokio::sync::mpsc; // 新增：用于Stream变体\nuse std::any::Any;\n\n// 1. 标准化的指令：UI层发给调度器的唯一入口\n#[derive(Debug, Clone)] // Command 仍然可以 Clone\npub enum Command {\n    ProcessText(String),\n    // 未来可以扩展: ProcessAudioChunk(Vec<f32>), etc.\n}\n\n// 2. 标准化的响应：调度器返回给UI层的唯一出口\n// 移除 Clone 派生，因为 mpsc::Receiver 不能 Clone\n#[derive(Debug)] // 只有 Debug，没有 Clone\npub enum Response {\n    Text(String),\n    FileToOpen(PathBuf),\n    Stream(mpsc::Receiver<String>), // 新增：用于流式文本\n    // ... etc.\n}\n\n// 3. 所有Agent必须遵守的行为准则 (Trait)\n// 我们需要async_trait来在trait中使用async fn\n#[async_trait]\npub trait Agent: Send + Sync {\n    fn name(&self) -> &'static str;\n    fn interests(&self) -> &[&'static str];\n    async fn handle_command(&self, command: &Command) -> Result<Response, anyhow::Error>;\n    \n    // 新增: 用于支持向下转型 (downcasting)\n    fn as_any(&self) -> &dyn Any;\n}"
        },
        {
            "file_path": "orchestrator/src/orchestrator.rs",
            "content": "use memos_core::{Agent, Command, Response};\nuse agent_memos::MemosAgent;\nuse std::sync::Arc;\n\n/// 中枢调度器\n/// 它的职责是管理所有的Agent，并根据指令分发任务\npub struct Orchestrator {\n    agents: Vec<Arc<dyn Agent>>,\n}\n\nimpl Orchestrator {\n    /// 创建一个新的调度器实例\n    pub fn new() -> Self {\n        let memos_agent = Arc::new(MemosAgent::new());\n\n        Self {\n            agents: vec![memos_agent],\n        }\n    }\n\n    /// 处理指令的核心方法\n    pub async fn process_command(&self, command: Command) -> Result<Response, anyhow::Error> {\n        match command {\n            Command::ProcessText(text) => {\n                for agent in &self.agents {\n                    if agent.interests().iter().any(|interest| text.contains(interest)) {\n                        println!(\"[Orchestrator] Found interested agent: {}. Routing command...\", agent.name());\n                        // 注意：这里我们将 text 的所有权转移给新的 Command\n                        return agent.handle_command(&Command::ProcessText(text)).await;\n                    }\n                }\n                \n                println!(\"[Orchestrator] No agent found for this command.\");\n                Ok(Response::Text(\"抱歉，我暂时无法理解您的指令。\".to_string()))\n            }\n        }\n    }\n} // <--- 在这里补上缺失的右花括号！"
        },
        {
            "file_path": "orchestrator/src/lib.rs",
            "content": "// orchestrator/src/lib.rs\nmod prompts; // 引入我们新的prompts模块\nuse agent_memos::MemosAgent; \nuse memos_core::{Agent, Command, Response};\nuse reqwest::Client;\nuse serde::Deserialize;\nuse serde_json::json;\n\n// 定义分类器的响应结构\n#[derive(Deserialize, Debug)]\nstruct ClassificationResponse {\n    intent: String,\n}\n\n// 定义分类器的结构体\npub struct IntentClassifier {\n    client: Client,\n    llm_url: String,\n}\n\nimpl IntentClassifier {\n    pub fn new(llm_url: &str) -> Self {\n        Self {\n            client: Client::new(),\n            llm_url: llm_url.to_string(),\n        }\n    }\n\n    // 分类方法\n    pub async fn classify(&self, text: &str) -> Result<String, anyhow::Error> {\n        println!(\"[IntentClassifier] Classifying text: '{}'\", text);\n        let prompt = prompts::get_intent_classification_messages(text);\n        let gbnf_schema = prompts::get_intent_gbnf_schema();\n\n        // 构建符合 llama.cpp /completion 接口的请求体\n        let request_body = json!({\n            \"prompt\": prompt,\n            \"n_predict\": 128,\n            \"temperature\": 0.1,\n            \"grammar\": gbnf_schema // 使用GBNF schema强制输出格式\n        });\n        \n        let response_text = self.client.post(&self.llm_url)\n            .json(&request_body)\n            .send()\n            .await?\n            .text()\n            .await?;\n\n        // llama.cpp /completion 返回的 content 字段是字符串，需要我们自己解析\n        // 假设返回的response_text是 `{\"content\":\"{\\\"intent\\\": \\\"RecallIntent\\\"}\"}` 这种形式\n        let response_json: serde_json::Value = serde_json::from_str(&response_text)?;\n        let content_str = response_json[\"content\"].as_str().ok_or_else(|| anyhow::anyhow!(\"Missing 'content' in LLM response\"))?;\n        \n        let classification: ClassificationResponse = serde_json::from_str(content_str)?;\n\n        println!(\"[IntentClassifier] Classified intent as: {}\", classification.intent);\n        Ok(classification.intent)\n    }\n}\n\npub struct Orchestrator {\n    agents: Vec<Box<dyn Agent>>,\n    classifier: IntentClassifier,\n}\n\nimpl Orchestrator {\n    pub fn new(agents: Vec<Box<dyn Agent>>, classifier_llm_url: &str) -> Self {\n        Self { \n            agents,\n            classifier: IntentClassifier::new(classifier_llm_url),\n        }\n    }\n\n    pub async fn dispatch(&self, command: &Command) -> Result<Response, anyhow::Error> {\n        match command {\n            Command::ProcessText(text) => {\n                let intent = self.classifier.classify(text).await?;\n\n                // 在这里，我们找到 memos_agent\n                // 一个更健壮的设计会使用 agent.name() 来查找，但现在我们只有一个，所以直接取第一个\n                if let Some(agent) = self.agents.get(0) {\n                    // 我们需要将 Box<dyn Agent> 向下转型为 MemosAgent\n                    if let Some(memos_agent) = agent.as_any().downcast_ref::<MemosAgent>() {\n                        return match intent.as_str() {\n                            \"SaveIntent\" => {\n                                memos_agent.save(text).await?;\n                                Ok(Response::Text(\"好的，已经记下了。\".to_string()))\n                            },\n                            \"RecallIntent\" => {\n                                memos_agent.recall(text).await\n                            },\n                            _ => {\n                                Ok(Response::Text(\"抱歉，我暂时无法理解您的意图。\".to_string()))\n                            }\n                        }\n                    }\n                }\n\n                // 如果找不到或转型失败，返回错误\n                Err(anyhow::anyhow!(\"Could not find or downcast MemosAgent\"))\n            }\n        }\n    }\n}"
        },
        {
            "file_path": "orchestrator/src/prompts.rs",
            "content": "// orchestrator/src/prompts.rs\n\nuse serde_json::json; // 恢复导入 json! 宏\n\npub fn get_intent_classification_messages(user_query: &str) -> String {\n    let system_prompt = r#\"You are a highly efficient user intent classifier. Your sole purpose is to analyze the user's query and classify it into one of two categories: `SaveIntent` or `RecallIntent`.\n\n**Category Definitions:**\n- **`SaveIntent`**: The user wants to save, record, or remember a piece of information. Keywords: \"记一下\", \"提醒我\", \"别忘了\", or statements of fact.\n- **`RecallIntent`**: The user is asking a question, trying to retrieve information. Keywords: \"查询\", \"查找\", \"是什么\", \"如何\", or any sentence ending with a question mark.\n\n**Your Output MUST be a valid JSON object with the following structure:**\n```json\n{\n  \"intent\": \"string, one of [SaveIntent, RecallIntent]\"\n}\n```\n**No other text, explanations, or markdown formatting outside of this JSON object.**\n\n**Examples:**\n\n<example>\n  <user_query>我最喜欢的编程语言是Rust</user_query>\n  <assistant_json_output>\n  {\"intent\": \"SaveIntent\"}\n  </assistant_json_output>\n</example>\n\n<example>\n  <user_query>查询明天下午的会议安排？</user_query>\n  <assistant_json_output>\n  {\"intent\": \"RecallIntent\"}\n  </assistant_json_output>\n</example>\n\n<example>\n  <user_query>Rust的内存管理如何运作</user_query>\n  <assistant_json_output>\n  {\"intent\": \"RecallIntent\"}\n  </assistant_json_output>\n</example>\n\"#;\n\n    // 我们不再需要 messages 变量，直接构建最终的 prompt 字符串\n    // 这样既简洁，也避免了 unused_variable 警告\n    format!(\n        \"{}\\n\\nUser Query: \\\"{}\\\"\\n\\nJSON Output:\",\n        system_prompt,\n        user_query\n    )\n}\n\n// 从您提供的文件中学习到的GBNF语法，这是保证输出的关键！\npub fn get_intent_gbnf_schema() -> &'static str {\n    r#\"\nroot   ::= object\nobject ::= \"{\" ws \"\\\"intent\\\"\" ws \":\" ws intent_enum ws \"}\"\nintent_enum ::= \"\\\"SaveIntent\\\"\" | \"\\\"RecallIntent\\\"\"\nws ::= ([ \\t\\n\\r])*\n\"#\n}\n"
        },
        {
            "file_path": "memos_cli/src/main.rs",
            "content": "use orchestrator::Orchestrator;\nuse agent_memos::MemosAgent;\nuse memos_core::{Agent, Command, Response};\nuse rustyline::DefaultEditor;\nuse std::any::Any;\n#[tokio::main]\nasync fn main() -> Result<(), anyhow::Error> {\n    println!(\"--- Memos Agent CLI Initializing ---\");\n\n    // 我们需要两个URL：一个给Agent（Qdrant），一个给分类器（LLM）\n    let qdrant_url = \"http://localhost:6334\";\n    // 注意：分类器也使用我们的指令模型\n    let classifier_llm_url = \"http://localhost:8282/completion\"; // 使用 /completion 接口\n\n    let memos_agent = MemosAgent::new(qdrant_url).await?;\n    let agents: Vec<Box<dyn Agent>> = vec![Box::new(memos_agent)];\n    println!(\"Agents loaded: {} agent(s)\", agents.len());\n\n    // 使用新的构造函数\n    let orchestrator = Orchestrator::new(agents, classifier_llm_url);\n    println!(\"Orchestrator created.\");\n    println!(\"\\n欢迎使用 Memos 智能助理 (CLI版)\");\n    println!(\"请输入您的指令 (例如: '帮我记一下明天要开会'), 输入 'exit' 或按 Ctrl+C 退出。\");\n\n    let mut rl = DefaultEditor::new()?;\n\n    loop {\n        let readline = rl.readline(\"> \");\n        match readline {\n            Ok(line) => {\n                let input = line.trim();\n                let _ = rl.add_history_entry(input);\n\n                if input.is_empty() {\n                    continue;\n                }\n                if input.eq_ignore_ascii_case(\"exit\") {\n                    break;\n                }\n\n                let command = Command::ProcessText(input.to_string());\n                println!(\"[CLI] Sending command to orchestrator...\");\n\n                let result = orchestrator.dispatch(&command).await;\n\n                println!(\"\\n[助理]:\");\n                match result {\n                    Ok(response) => {\n                        match response {\n                            Response::Text(text) => {\n                                // 如果是普通文本响应，直接打印\n                                println!(\"{}\", text);\n                            }\n                            Response::FileToOpen(path) => {\n                                // 处理打开文件请求\n                                println!(\"请求打开文件: {:?}\", path);\n                            }\n                            Response::Stream(mut receiver) => {\n                                // 新增：用于过滤 <think> 标签的状态\n                                let mut is_thinking = false;\n                                let mut full_response = String::new(); // 用于拼接完整响应，以便处理标签\n\n                                while let Some(token) = receiver.recv().await {\n                                    if token.is_empty() { // 流结束信号\n                                        break;\n                                    }\n                                    full_response.push_str(&token);\n\n                                    // 持续处理，直到无法再找到完整的 <think> 或 </think> 标签\n                                    loop {\n                                        if !is_thinking {\n                                            if let Some(start_pos) = full_response.find(\"<think>\") {\n                                                // 打印标签前的内容\n                                                print!(\"{}\", &full_response[..start_pos]);\n                                                // 更新状态，并移除已处理的部分（包括标签）\n                                                is_thinking = true;\n                                                if let Some(end_pos) = full_response[start_pos..].find(\"</think>\") {\n                                                    // 如果在同一批次中找到了结束标签\n                                                    let end_in_slice = start_pos + end_pos + \"</think>\".len();\n                                                    full_response.drain(..end_in_slice);\n                                                    is_thinking = false;\n                                                    continue; // 继续循环，处理剩余的字符串\n                                                } else {\n                                                    // 如果只找到了开始标签\n                                                    full_response.drain(..); // 清空已处理部分\n                                                    break; // 等待更多token\n                                                }\n                                            }\n                                        }\n                                        \n                                        if is_thinking {\n                                            if let Some(end_pos) = full_response.find(\"</think>\") {\n                                                // 找到了结束标签，更新状态并移除已处理部分\n                                                is_thinking = false;\n                                                full_response.drain(..(end_pos + \"</think>\".len()));\n                                                continue; // 继续循环，处理剩余的字符串\n                                            } else {\n                                                // 仍在思考中，清空buffer，不打印\n                                                full_response.drain(..);\n                                                break; // 等待更多token\n                                            }\n                                        }\n\n                                        // 如果没有在思考，打印剩余内容并清空\n                                        if !is_thinking && !full_response.is_empty() {\n                                            print!(\"{}\", full_response);\n                                            full_response.clear();\n                                        }\n                                        break; // 没有更多标签可以处理，跳出内部循环\n                                    }\n                                    \n                                    // 刷新标准输出\n                                    use std::io::{self, Write};\n                                    io::stdout().flush().unwrap();\n                                }\n\n                                // 打印最后剩余的内容（如果有）\n                                if !is_thinking && !full_response.is_empty() {\n                                    print!(\"{}\", full_response);\n                                }\n                                println!(); // 流结束时打印一个换行符\n                            }\n                        }\n                    },\n                    Err(e) => {\n                        eprintln!(\"发生错误: {}\", e);\n                    }\n                }\n                println!();\n            }\n            Err(_) => {\n                break;\n            }\n        }\n    }\n\n    println!(\"感谢使用，再见！\");\n    Ok(())\n}"
        }
    ],
    "dependencies": {}
}